{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SMITE is a third-person MOBA developed by Titan Forge Games. In the primary competitive mode of SMITE, players on teams of five select combinations of deities from a pool of over 100, and then must choose 6 items to purchase from a pool of over 250+ items throughout the game. This project focuses on the second of these challenges, attempting to provide a beginner-friendly guide to which items are currently performing well on particular deities.\n",
    "\n",
    "There is a plethora of information available from SMITE's developer API, including kills, deaths, and assists, damage dealt, taken, and mitigated, and team and self healing. To begin, I will explore the connections between a player's performance statistics and their likelihood of victory.\n",
    "\n",
    "I will investigate both engineered features (such as K+A / D, or DM + SH / DT, or any other interesting combinations) alongside the raw features themselves to see if there is a linear or nonlinear relationship between these features and victory.\n",
    "\n",
    "Next, I will explore the relationship between a player's performance and the items they ended the game with. While I cannot see the items purchased or sold throughout the game, the structure of the in-game economy discourages selling most purchased items. As such, this is the highest resolution data available. Additionally, I prune my information (restricting to t3+ items) to prevent skewing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sbn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "from typing import Any, Dict, NamedTuple\n",
    "import os\n",
    "from copy import deepcopy\n",
    "\n",
    "from utilities import data_to_df, data_to_training_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 112/112 [00:45<00:00,  2.45it/s]\n"
     ]
    }
   ],
   "source": [
    "training_dfs = []\n",
    "all_dfs = []\n",
    "root = 'P:/SmiteData/conquest_match_data'\n",
    "files = os.listdir(root)\n",
    "for file in tqdm(files):\n",
    "    training_df, scaler = data_to_training_df(os.path.join(root,file))\n",
    "    training_dfs.append(training_df)\n",
    "    all_dfs.append(data_to_df(os.path.join(root, file), scaler))\n",
    "    \n",
    "df = training_dfs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's plot our raw features to see any visual correlations between them and victory\n",
    "for col in col_names:\n",
    "    if col == 'BIAS' or col == 'win_status' or col == 'match_id':\n",
    "        continue\n",
    "    sbn.boxplot(data=df, x='win_status', y=col)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From these plots we can clearly see that many statistics' distributions are markedly different for a win than a loss, indicating that there may be a correlation between a player's \"performance data\" and their chance at a victory. Let's see what all of these data points remapped into a 2-D space looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_d = TSNE(random_state=0, n_jobs=-1).fit_transform(df.values[:,1:-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "x = [x[0] for x in two_d]\n",
    "y = [y[1] for y in two_d]\n",
    "c = ['tab:blue' if e == 1 else 'tab:red' for e in df.values[:,-2]]\n",
    "plt.scatter(x,y, c=c, alpha=0.3)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once again, the data is seperable between \"unlikely to win\" and \"likely to win\", indicating a function should fit it well. First, let's try fitting a linear function, then see how much better we can do with a nonlinear function!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obv, first step is to split into train - test\n",
    "x_train, x_test, y_train, y_test = train_test_split(df.values[:,:-2], df.values[:,-2], test_size=0.33, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_lrc = {\n",
    "    'C': [10 ** x for x in range(-5,0)]\n",
    "}\n",
    "# NOTE: LOOK INTO LR_CV (the cross validated version of this, check diff params)\n",
    "lrc = LogisticRegression(random_state=0)\n",
    "clf_lrc = GridSearchCV(lrc, parameters_lrc, n_jobs=-1)\n",
    "clf_lrc.fit(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_df = pd.DataFrame(clf_lrc.cv_results_)\n",
    "cl_df.loc[cl_df['rank_test_score'] == 1]\n",
    "# NOTE: best params are C=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_l = clf_lrc.predict(df.values[:,:-2])\n",
    "clf_lrc.score(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "x = [x[0] for x in two_d]\n",
    "y = [y[1] for y in two_d]\n",
    "c = ['tab:blue' if e == 1 else 'tab:red' for e in new_l]\n",
    "c = [e if df.values[:,-2][idx] == new_l[idx] else 'tab:olive' for idx,e in enumerate(c)]\n",
    "plt.scatter(x,y, c=c, alpha=0.3)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters_rbf = {\n",
    "    'kernel': ['rbf'],\n",
    "    'C': [10 ** x for x in range(-3, 3)],\n",
    "    'gamma': [10 ** x for x in range(-3, 3)],\n",
    "}\n",
    "svm = SVC(random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_rbf = GridSearchCV(svm, parameters_rbf, n_jobs=-1)\n",
    "clf_rbf.fit(x_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cr_df = pd.DataFrame(clf_rbf.cv_results_)\n",
    "cr_df.loc[cr_df['rank_test_score'] == 1]\n",
    "# NOTE: best params are C=100, gamma=0.001, kernel=rbf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_l = clf_rbf.predict(df.values[:,:-2])\n",
    "clf_rbf.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.cla()\n",
    "x = [x[0] for x in two_d]\n",
    "y = [y[1] for y in two_d]\n",
    "c = ['tab:blue' if e == 1 else 'tab:red' for e in new_l]\n",
    "c = [e if df.values[:,-2][idx] == new_l[idx] else 'tab:olive' for idx,e in enumerate(c)]\n",
    "plt.scatter(x,y, c=c, alpha=0.3)\n",
    "# plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I will do some visual exploration of the data, examining the characteristics of each statistic and how it correlates to victory for a particular diety. Once the structure is complete, I intend to check it out with one diety of each class.\n",
    "\n",
    "Next, I'd like to determine whether a linear fitter will work for the data or if a non-linear model is required. SGDC for linear, SVMC for non-linear.\n",
    "\n",
    "After that, I need to determine if / how any data adjustment / de-fuzzing affects the final item classification accuracy. (essentially, does \"correcting\" the performance data labelling favorably impact the item classification accuracy?)\n",
    "\n",
    "After that, maybe explore different classifiers for items and performance, see if you can accurately determine the performance statistics based upon the items (this would prove the performance / item correlation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, I want to see if I can get even better prediction by seeing all the statistics of all the players on a team."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Determine the noise caused by teammates and if that noise can be meaningfully reduced by taking the prediction of the linear model rather than the actual win label**\n",
    "\n",
    "Steps:\n",
    "* Load all gods, make predictions for every entry.\n",
    "* Assemble all 5-man teams\n",
    "* train a classifier to predict team victory based on probability of individual player victory\n",
    "* See if we can do some mix-and-match, substituting \".5\" percent victory predictions for teammates and seeing what the output is.\n",
    "* Determine if the output of the linear classifier matches the victory predictions for teammates with a range of probabilities, from 0.25 to 0.75."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Current Idea: First, predict every individual player's likelihood of victory. Next, get the percentiles of all the probabilities (lets say by 10). Finally, count the number of players on each team who are in each percentile and then put that into a regression classifier targeting the victory label. Hopefully, this will give me a 95% plus accuracy, I'd love 99% to 100%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 112/112 [00:03<00:00, 33.78it/s]\n"
     ]
    }
   ],
   "source": [
    "predict_col_names = (\n",
    "    'match_id',\n",
    "    'prediction',\n",
    "    'win_status',\n",
    ")\n",
    "\n",
    "predictions_dfs = []\n",
    "for i in tqdm(range(len(all_dfs))):\n",
    "    training_df = training_dfs[i]\n",
    "    all_df = all_dfs[i]\n",
    "    lr = LogisticRegression(random_state=0, C=0.1, n_jobs=-1)\n",
    "    lr.fit(training_df.values[:,:-2], training_df.values[:,-2].ravel())\n",
    "    predictions_dfs.append(\n",
    "        pd.DataFrame(\n",
    "            np.hstack((\n",
    "                all_df.values[:,-1].reshape((all_df.values.shape[0], 1)),\n",
    "                np.array([\n",
    "                    x[1]\n",
    "                    for x in lr.predict_proba(all_df.values[:,:-2])\n",
    "                ]).reshape(all_df.values.shape[0], 1),\n",
    "                all_df.values[:,-2].reshape((all_df.values.shape[0], 1)),\n",
    "            )),\n",
    "            columns=predict_col_names,\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = pd.concat(predictions_dfs)\n",
    "predictions.sort_values('match_id')\n",
    "percentiles = np.percentile(predictions.values[:, 1], list(range(0,101,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████| 567230/567230 [04:15<00:00, 2216.83it/s]\n"
     ]
    }
   ],
   "source": [
    "team_noise = {}\n",
    "num_rows = range(predictions.values.shape[0])\n",
    "for i in tqdm(num_rows):\n",
    "    row = predictions.iloc[i]\n",
    "    match_id = row['match_id']\n",
    "    try:\n",
    "        team_noise[match_id].append(tuple(row[['prediction', 'win_status']]))\n",
    "    \n",
    "    except KeyError:\n",
    "        team_noise[match_id] = [tuple(row[['prediction', 'win_status']])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56723"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(team_noise.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1124201970.0,\n",
       "  [(0.8611375738963265, 1.0),\n",
       "   (0.08374994558023388, 0.0),\n",
       "   (0.9881562278147311, 1.0),\n",
       "   (0.12842607480443832, 0.0),\n",
       "   (0.9524856538467421, 1.0),\n",
       "   (0.9289861508657391, 1.0),\n",
       "   (0.9951852235078725, 1.0),\n",
       "   (0.024370638679009054, 0.0),\n",
       "   (0.09077516541573394, 0.0),\n",
       "   (0.10138273383499986, 0.0)]),\n",
       " (1124203678.0,\n",
       "  [(0.022827118188160918, 0.0),\n",
       "   (0.0014696720100761422, 0.0),\n",
       "   (0.011506460408757049, 0.0),\n",
       "   (0.9995904919845279, 1.0),\n",
       "   (0.984851284304099, 1.0),\n",
       "   (0.9904482309271895, 1.0),\n",
       "   (0.9561156451032152, 1.0),\n",
       "   (0.09834561562747843, 0.0),\n",
       "   (0.21504237587129718, 1.0),\n",
       "   (0.023342706447793696, 0.0)]),\n",
       " (1124203696.0,\n",
       "  [(0.9995494615744414, 1.0),\n",
       "   (0.868710595959615, 1.0),\n",
       "   (0.9776702140147104, 1.0),\n",
       "   (0.01627769931759985, 0.0),\n",
       "   (0.003139414500156998, 0.0),\n",
       "   (0.019261372645486077, 0.0),\n",
       "   (0.9924365761746903, 1.0),\n",
       "   (0.9819352387315695, 1.0),\n",
       "   (0.006789046050023316, 0.0),\n",
       "   (0.010551590324919553, 0.0)])]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(team_noise.items())[10000:10003]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "smitebuilder",
   "language": "python",
   "name": "smitebuilder"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
